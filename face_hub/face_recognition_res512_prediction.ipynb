{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "Untitled"
    },
    "language_info": {
      "name": "Python",
      "version": "3.7.4-final"
    },
    "kernelspec": {
      "name": "python37464bitbaseconda4ee9745dfb6342f2b1985c4a4af6c263",
      "display_name": "Python 3.7.4 64-bit ('base': conda)"
    },
    "colab": {
      "name": "face_recognition_res512.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, Flatten, Dense, Input, add\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Index(['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n       'Wearing_Necklace', 'Wearing_Necktie', 'Young'],\n      dtype='object')\n     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n0  000001.jpg                 0                1           1                0   \n1  000002.jpg                 0                0           0                1   \n2  000003.jpg                 0                0           0                0   \n3  000004.jpg                 0                0           1                0   \n4  000005.jpg                 0                1           1                0   \n\n   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  Sideburns  Smiling  \\\n0     0      0         0         0           0  ...          0        1   \n1     0      0         0         1           0  ...          0        1   \n2     0      0         1         0           0  ...          0        0   \n3     0      0         0         0           0  ...          0        0   \n4     0      0         1         0           0  ...          0        0   \n\n   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n0              1          0                 1            0                 1   \n1              0          0                 0            0                 0   \n2              0          1                 0            0                 0   \n3              1          0                 1            0                 1   \n4              0          0                 0            0                 1   \n\n   Wearing_Necklace  Wearing_Necktie  Young  \n0                 0                0      1  \n1                 0                0      1  \n2                 0                0      1  \n3                 1                0      1  \n4                 0                0      1  \n\n[5 rows x 41 columns]\n"
        }
      ],
      "source": [
        "p = Path('celeba-dataset')\n",
        "\n",
        "df = pd.read_csv(p / 'list_attr_celeba.csv')\n",
        "columns = df.columns[1:]\n",
        "\n",
        "df.replace(-1, 0, inplace=True)\n",
        "print(columns)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                rotation_range = 40,\n",
        "                width_shift_range = 0.2,\n",
        "                height_shift_range = 0.2,\n",
        "                brightness_range = (0.3, 1.0),\n",
        "                rescale = 1/255,\n",
        "                shear_range = 0.2,\n",
        "                zoom_range = 0.2,\n",
        "                horizontal_flip = True\n",
        "                )\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(141819, 41)\n(42546, 41)\n(18234, 41)\n          image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  \\\n96740   096741.jpg                 0                0           1   \n140755  140756.jpg                 0                0           1   \n194592  194593.jpg                 0                0           0   \n129450  129451.jpg                 0                0           0   \n95721   095722.jpg                 0                1           1   \n\n        Bags_Under_Eyes  Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  \\\n96740                 0     0      0         0         0           0  ...   \n140755                0     0      0         0         0           0  ...   \n194592                0     0      1         0         0           1  ...   \n129450                1     0      0         0         1           0  ...   \n95721                 0     0      0         0         0           0  ...   \n\n        Sideburns  Smiling  Straight_Hair  Wavy_Hair  Wearing_Earrings  \\\n96740           0        1              0          0                 0   \n140755          0        0              0          1                 0   \n194592          0        0              1          0                 0   \n129450          0        0              1          0                 0   \n95721           0        0              0          1                 0   \n\n        Wearing_Hat  Wearing_Lipstick  Wearing_Necklace  Wearing_Necktie  \\\n96740             0                 1                 0                0   \n140755            0                 1                 0                0   \n194592            0                 1                 0                0   \n129450            0                 0                 0                0   \n95721             0                 1                 0                0   \n\n        Young  \n96740       1  \n140755      1  \n194592      1  \n129450      0  \n95721       1  \n\n[5 rows x 41 columns]\n"
        }
      ],
      "source": [
        "train_y, test_y = train_test_split(df, test_size = 0.3)\n",
        "valid_y, test_y = train_test_split(test_y, test_size = 0.7)\n",
        "print(train_y.shape)\n",
        "print(test_y.shape)\n",
        "print(valid_y.shape)\n",
        "print(train_y.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Found 141819 validated image filenames.\nFound 18234 validated image filenames.\nFound 42546 validated image filenames.\n"
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "                dataframe = train_y,\n",
        "                directory = p / 'img_align_celeba',\n",
        "                x_col = 'image_id',\n",
        "                y_col = columns,\n",
        "                batch_size = 32,\n",
        "                seed = 42,\n",
        "                shuffle = True,\n",
        "                class_mode = 'other',\n",
        "                target_size = (64, 64)\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "                dataframe = valid_y,\n",
        "                directory = p / 'img_align_celeba',\n",
        "                x_col = 'image_id',\n",
        "                y_col = columns,\n",
        "                batch_size = 64,\n",
        "                seed = 42,\n",
        "                shuffle = True,\n",
        "                class_mode = 'other',\n",
        "                target_size = (64, 64)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                dataframe = test_y,\n",
        "                directory = p / 'img_align_celeba',\n",
        "                x_col = 'image_id',\n",
        "                batch_size = 1,\n",
        "                seed = 42,\n",
        "                shuffle = False,\n",
        "                class_mode = None,\n",
        "                target_size = (64, 64)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def res_block(layer, filters, stride=(2,2)):\n",
        "    x = BatchNormalization()(layer)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, stride, activation = 'relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, stride, activation = 'relu')(x)\n",
        "    return x\n",
        "# I switched all activations to relu as it's the standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
        }
      ],
      "source": [
        "inputs = Input(shape=(64, 64, 3))\n",
        "saved_inputs = inputs\n",
        "\n",
        "# I've left out the initial batch normalization to keep variance in the input information.\n",
        "# I've also removed the regularizers.\n",
        "x = Conv2D(64, (1, 1), use_bias=False)(inputs)\n",
        "\n",
        "x = BatchNormalization(axis = 1, epsilon = 0.0001, momentum = 0.95)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding=\"same\", use_bias=False)(x) # This layer is a bottleneck.\n",
        "# Same padding prevents downsampling so we can add the original input back in later.\n",
        "\n",
        "x = BatchNormalization(axis = 1, epsilon = 0.0001, momentum = 0.95)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(128, (1, 1), use_bias=False)(x)\n",
        "\n",
        "saved_inputs = Conv2D(128, (1, 1), use_bias=False)(saved_inputs)\n",
        "x = add([x, saved_inputs])\n",
        "\n",
        "y = res_block(x, 64)\n",
        "x = Conv2D(64, (2, 2), activation = 'relu')(x)\n",
        "x = Conv2D(64, (2, 2), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "y = res_block(x, 64)\n",
        "x = Conv2D(64, (2, 2), activation = 'relu')(x)\n",
        "x = Conv2D(64, (2, 2), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "y = res_block(x, 128, (1, 1))\n",
        "x = Conv2D(128, (1, 1), activation = 'relu')(x)\n",
        "x = Conv2D(128, (1, 1), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "y = res_block(x, 128, (1, 1))\n",
        "x = Conv2D(128, (1, 1), activation = 'relu')(x)\n",
        "x = Conv2D(128, (1, 1), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "x = Dropout(0.2)(x)\n",
        "x = ZeroPadding2D((1,1))(x)\n",
        "x = MaxPooling2D((2,2), strides=(2,2))(x)\n",
        "# I've added dropout and 'blurred' the image with max pooling before the last half of the network.\n",
        "\n",
        "y = res_block(x, 256, (2, 2))\n",
        "x = Conv2D(256, (2, 2), activation = 'relu')(x)\n",
        "x = Conv2D(256, (2, 2), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "y = res_block(x, 256, (2, 2))\n",
        "x = Conv2D(256, (2, 2), activation = 'relu')(x)\n",
        "x = Conv2D(256, (2, 2), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "y = res_block(x, 512, (2, 2))\n",
        "x = Conv2D(512, (2, 2), activation = 'relu')(x)\n",
        "x = Conv2D(512, (2, 2), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "y = res_block(x, 512, (2, 2))\n",
        "x = Conv2D(512, (2, 2), activation = 'relu')(x)\n",
        "x = Conv2D(512, (2, 2), activation = 'relu')(x)\n",
        "x = add([x, y])\n",
        "\n",
        "x = BatchNormalization(axis = 1, epsilon = 0.0001, momentum = 0.95)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = AveragePooling2D(pool_size = (2, 2), strides = (2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "output = Dense(40, activation = 'sigmoid', kernel_initializer='he_normal')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Model(inputs, output, name=\"ResNet_for_faces\")\n",
        "sgd = SGD(momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "284\n"
        }
      ],
      "source": [
        "train_steps = train_generator.n // train_generator.batch_size\n",
        "valid_steps = validation_generator.n // validation_generator.batch_size\n",
        "test_steps = test_generator.n // test_generator.batch_size\n",
        "\n",
        "print(valid_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "colab_type": "code",
        "id": "KxbwG2yv90qe",
        "outputId": "315907b6-cd80-4f70-c295-8b8a55fdbae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "4430/4431 [============================>.] - ETA: 0s - loss: 0.4167 - acc: 0.8132Epoch 1/5\n",
            " 284/4431 [>.............................] - ETA: 12:04 - loss: 0.3847 - acc: 0.8285\n",
            "Epoch 00001: val_loss improved from inf to 0.38467, saving model to weights.hdf5\n",
            "4431/4431 [==============================] - 1333s 301ms/step - loss: 0.4167 - acc: 0.8132 - val_loss: 0.3847 - val_acc: 0.8285\n",
            "Epoch 2/5\n",
            "4430/4431 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8303Epoch 1/5\n",
            " 284/4431 [>.............................] - ETA: 11:51 - loss: 0.3689 - acc: 0.8347\n",
            "Epoch 00002: val_loss improved from 0.38467 to 0.36886, saving model to weights.hdf5\n",
            "4431/4431 [==============================] - 1319s 298ms/step - loss: 0.3792 - acc: 0.8303 - val_loss: 0.3689 - val_acc: 0.8347\n",
            "Epoch 3/5\n",
            "4430/4431 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8421Epoch 1/5\n",
            " 284/4431 [>.............................] - ETA: 11:51 - loss: 0.3515 - acc: 0.8438\n",
            "Epoch 00003: val_loss improved from 0.36886 to 0.35150, saving model to weights.hdf5\n",
            "4431/4431 [==============================] - 1318s 297ms/step - loss: 0.3533 - acc: 0.8421 - val_loss: 0.3515 - val_acc: 0.8438\n",
            "Epoch 4/5\n",
            "4430/4431 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.8618Epoch 1/5\n",
            " 284/4431 [>.............................] - ETA: 11:51 - loss: 0.2939 - acc: 0.8708\n",
            "Epoch 00004: val_loss improved from 0.35150 to 0.29391, saving model to weights.hdf5\n",
            "4431/4431 [==============================] - 1318s 298ms/step - loss: 0.3144 - acc: 0.8618 - val_loss: 0.2939 - val_acc: 0.8708\n",
            "Epoch 5/5\n",
            "4430/4431 [============================>.] - ETA: 0s - loss: 0.2899 - acc: 0.8733Epoch 1/5\n",
            " 284/4431 [>.............................] - ETA: 11:51 - loss: 0.2761 - acc: 0.8797\n",
            "Epoch 00005: val_loss improved from 0.29391 to 0.27605, saving model to weights.hdf5\n",
            "4431/4431 [==============================] - 1318s 298ms/step - loss: 0.2899 - acc: 0.8733 - val_loss: 0.2761 - val_acc: 0.8797\n"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(generator = train_generator,\n",
        "                    steps_per_epoch = train_steps,\n",
        "                    epochs = 5,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [EarlyStopping(monitor='val_loss', patience=2, min_delta=0.0001, restore_best_weights=True),\n",
        "                    ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True),\n",
        "                    CSVLogger('log.csv', append=True, separator=';')],\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps = valid_steps\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights(r'C:\\Users\\user\\Desktop\\Revature\\Projects\\face_recognition\\res_512_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0.19457582 0.10393882 0.17653105 0.26333618 0.08533549 0.19610411\n  0.21308208 0.2839433  0.18760109 0.07670495 0.32755396 0.17299652\n  0.12269059 0.13736796 0.11152101 0.12020501 0.12962231 0.11064738\n  0.07986185 0.21210691 0.6474339  0.3691056  0.14214575 0.1903778\n  0.7027931  0.1759311  0.13535953 0.15727514 0.11320087 0.02121565\n  0.1318909  0.17199785 0.2568685  0.16608894 0.15406975 0.44883415\n  0.09599724 0.08212063 0.09775853 0.6479239 ]]\n{0: ['Male', 'No_Beard', 'Young']}\n"
        }
      ],
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "import cv2\n",
        "\n",
        "image = cv2.imread(r'C:\\Users\\user\\Desktop\\Revature\\Projects\\face_recognition\\celeba-dataset\\img_align_celeba\\000019.jpg')\n",
        "image = cv2.resize(image, (64,64))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "prediction = model.predict(image)\n",
        "print(prediction)\n",
        "\n",
        "face_features = {}\n",
        "for x, pred in enumerate(prediction):\n",
        "    face_features[x] = []\n",
        "    for i, prob in enumerate(pred):\n",
        "        if prob >= 0.5:\n",
        "            face_features[x].append(columns[i])\n",
        "\n",
        "print(face_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "   24/42546 [..............................] - ETA: 7:04:46"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-14-0f413f5ec1b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1536\u001b[1;33m         verbose=verbose)\n\u001b[0m\u001b[0;32m   1537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_callback_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(x, y, sample_weights)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;31m# 1, 2, or 3-tuples from generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=unused-argument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_generator.reset()\n",
        "prediction = model.predict_generator(\n",
        "    test_generator,\n",
        "    steps = test_steps,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "colab_type": "code",
        "id": "Cx6OSny290rI",
        "outputId": "929e5e2f-3045-403a-8cbf-0f86d7a20642"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-92f68be843d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mface_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'face_predictions_res_net.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'face_predictions_res_net.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ],
      "source": [
        "face_features = {}\n",
        "for i, col in enumerate(columns):\n",
        "    face_features[col] = []\n",
        "    for pred in prediction:\n",
        "        face_features[col].append(pred[i])\n",
        "\n",
        "face_predictions = pd.DataFrame(face_features)\n",
        "\n",
        "face_predictions.to_csv('face_predictions_res_net.csv')\n",
        "files.download('face_predictions_res_net.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3Qm8sEwn90rV"
      },
      "outputs": [],
      "source": []
    }
  ]
}